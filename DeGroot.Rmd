---
title: "Naive learning"
author: "Raffaele di Costanzo, Wojciech Ma≈õlakiewicz"
date: "3/29/2021"
output: html_document
editor_options: 
  markdown: 
    wrap: 72
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## Introduction

Observing, analyzing and modeling social interactions constitutes a
substantial area of research in social sciences. The concept of social
network provides a robust and handy, graph-theory-based framework for
analyzing how people interact, communicate and form communities.

One special form of interaction that falls within the scope of this
framework is social learning - an umbrella term for encompassing a
variety of phenomenons including:

-   how groups of people form networks
-   how they influence each other in such networks
-   how their opinion relates to some objective truth
-   how those opinions evolve in the process of interactions.

Many mathematical models have been developed to formalize those issues.
Usually, every such model comprises of some social **structure** defining
how agents interact and an **updating rule** which determines how each
agent forms his own opinion, possibly by taking into account opinions of
others. Sometimes those two elements are closely tied together and are
difficult to distinguish but in general we may divide those models with
respect to the latter component into two following categories.

1. **Bayesian learning models**

The underlying assumption is agents update their believes using Bayes'
rule. Formally, given a parameter $\Theta$ (e.g. an opinion about a
political issue) and a signal $s$ (e.g. a news or opinion of others),
the updating procedure is given by
\begin{equation} 
P(\Theta|s) = \frac{P(s|\Theta)P(\Theta)}{P(s)}  ,
\end{equation} where $P(\Theta)$
is a prior probability which may be interpreted as a result of agents
own observations of the world. 

2. **Non-bayesian learning models**

This class of models usually incorporate a relatively more simple updating rule.
The most prominent example is the __DeGroot model__ [REFERENCE], sometimes known as
naive learning, which assumes that each agent updates her beliefs by taking an 
average of her neighbor's opinions (possibly, but not necessarily including her own opinion). Contrary to the Bayesian framework which might impose great cognitive abilities 
on agents which may be unrealistic to bear by real people, the DeGroot model 
provides a rule that is empirically justifiable in its simplicity but still flexible for further extensions.

In this short survey we will concentrate on the DeGroot model and provide a brief 
discussion of its various extensions found in the literature with particular focus
on their possible usage in modeling and simulation of phenomena combining information bubbles and polarization observed during the pandemics such as the anti-vaccine 
movements or plandemics conspiracy theory.

We will heavily rely on two exhaustive surveys [REFERENCE] and try to illustrate theoretical results with some simulations. 

## Summary of the experimental paper

## Basic model

In this section we will briefly present the basic version of the DeGroot model and introduce notation that we shall further use. 

We consider a _set of agents_ $N = {1,2, ..., n}$ who interact in discrete time $T = {1,2,...}$. At each time instant $t$ every (fixed) agent $i$ has his _opinion_ $x_i(t) \in [0,1]$ and _trust_ (weight) $w_{ij}$ towards every other agent $j \in N$. Let's denote with $x(t) = \left(x_1(t), x_2(t), ..., x_n(t)\right)$ a vector of agents' opinions or _opinion profile_ at time $t$. With such notation, each agent agent updates his opinion by averaging opinions of other agents, that is 
$$ x_i(t+1) = w_{i1}x_1(t) + w_{i2}x_2(t) + ... + w_{in}x_n(t) ,$$
where $\sum_j w_{ij} = 1$


In the most general form trust may depend both on time and the opinion profile. However, whenever it does not lead to confusion we will simply write $w_{ij}$ instead of $w_{ij}(t,x(t))$ to denote agents $i$ trust towards agent $j$. The trust between agents gives raise to the structure of their interactions which can be represented as a row stochastic matrix, where $W = [w_{ij}]$ which may be also viewed at an incidence matrix of a weighted directed graph. This allows us to apply elements of the sophisticated machinery of graph theory and Markov chains to analyzing social learning problems. 

In compact matrix notation our general model (GM) has the following components:

* a directed weighted graph of trust between agents: $G = (N,W)$
* an updating rule $x(t+1) = W(t,x(t))x(t) = W^tx(0)$ for $t \in T$

The main issues analyzed within this framework are _convergence_ of beliefs and _reaching consensus_. 

We say that the beliefs converge for a given matrix of weights $W$ whenever for every initial opinion profile $x(0) \in [0,1]^n$ the limit 
\[\lim_{t \to \infty} W^tx(0)\] exists.



TODO: consensus, theoretical results, simulation
```{r packages, include=FALSE}
requiredPackages = c("markovchain", "readr","diagram", "wesanderson", "expm") # list of required packages
for(i in requiredPackages){if(!require(i,character.only = TRUE)) install.packages(i)}
for(i in requiredPackages){if(!require(i,character.only = TRUE)) library(i,character.only = TRUE) } 

# Base on:
# 1. Taalaibekova, 2018 example 2.1
# 2. Janpu Hou https://rpubs.com/JanpuHou/326048

# The notation is based on Taalaibekova


# Simulation of the process
# Different type of notation of transaction matrix 
markov_chains_2 <-  function(M, x0, iter ){
  sym <- matrix(0, nrow = nrow(M), ncol =  iter )
  M_to_p_i <- M
  sym[,1] <- x0
    for(i in 2:iter) {
    
    sym[,i] <- M_to_p_i %*% x0 
    M_to_p_i <- M %*% M_to_p_i
  }
  return(sym)
}
```


## Extension 1

some description of extension 1

some equations

some theoretical results

some simulation

```{r extension 1 simulation, echo=TRUE}
markov_chains_4 <-  function(M, x0, iter, fA,fB,fC
                             ,noA = N*percA,noB = N*percB,noC = N*percC  ){
  sym <- matrix(0, nrow = nrow(M), ncol =  iter )
  M_to_p_i <- M
  sym[,1] <- x0
  for(i in 2:iter) {
    lA <- sapply(rep(i,noA),fA_con)
    lB <- sapply(rep(i,noB),fB_con)
    lC <- sapply(rep(i,noC),fC_con)
    lambdas = c(lA,lB,lC)
    sym[,i] <- ((1-lambdas)*diag(dim(M)[1]) + lambdas*M_to_p_i) %*% x0 
    M_to_p_i <- M %*% M_to_p_i
  }
  return(sym)
}
```

```{r extension 1, include=FALSE}



make_matrix <- function(dim,vals){
  M = matrix(vals,nrow = dim, byrow = TRUE)
  return(M)
}

trustAA = 3/4
trustAB = 0
trustAC = 1/4

trustBB = 3/4
trustBA = 0
trustBC = 2/8

trustCC = 0
trustCA = 1/5
trustCB = 4/5

percA = 0.3
percB = 0.5
percC = 0.2

N = 100

AA = make_matrix(N*percA,c(rep(trustAA/(N*percA),(N*percA)^2)))
AB = make_matrix(N*percA,c(rep(trustAB/(N*percB),(N*percB)*(N*percA))))
AC = make_matrix(N*percA,c(rep(trustAC/(N*percC),(N*percC)*(N*percA))))

rowA = cbind(AA,AB,AC)

BA = make_matrix(N*percB,c(rep(trustBA/(N*percA),(N*percB)*(N*percA))))
BB = make_matrix(N*percB,c(rep(trustBB/(N*percB),(N*percB)*(N*percB))))
BC = make_matrix(N*percB,c(rep(trustBC/(N*percC),(N*percB)*(N*percC))))

rowB = cbind(BA,BB,BC)

CA = make_matrix(N*percC,c(rep(trustCA/(N*percA),(N*percC)*(N*percA))))
CB = make_matrix(N*percC,c(rep(trustCB/(N*percB),(N*percC)*(N*percB))))
CC = make_matrix(N*percC,c(rep(trustCC/(N*percC),(N*percC)*(N*percC))))

rowC = cbind(CA,CB,CC)

W= rbind(rowA,rowB,rowC)

distA = rbeta(N*percA,1,7)
distB = rbeta(N*percB,7,1)
distC = rbeta(N*percC,7,7)


fA_con = function(i){ return(1 - 0.9/16 *i + runif(1,-0.01,0.01)) }
fB_con = function(i){ return(1 - 0.9/16 *i + runif(1,-0.01,0.01)) }
fC_con = function(i){ return(runif(1,0.6,0.9) ) }

  
X_0 <- c(distA,distB,distC)
t <- 15 # Iteration of interactions 
sym <- as.data.frame(markov_chains_4(W, X_0 ,t,fA_con,fB_con,fC_con))
X_fin = sym[,t]
vacc_0 <- sum(X_0>0.5)/length(X_0)
vacc_fin <- sum(X_fin>0.5)/length(X_fin)


sym[1:(N*percA),t+1] <- rep("Agent A",N*percA)
sym[(N*percA+1):(N*percA+N*percB),t+1] <- rep("Agent B",N*percB)
sym[(N*percA+N*percB+1):(N*percA+N*percB+N*percC),t+1] <- rep("Agent C",N*percC)

#row.names(sym)[1:(N*percA)] <- rep("Agent A",N*percA)
#row.names(sym)[(N*percA+1):(N*percA+N*percB)] <- rep("Agent B",N*percB)
#row.names(sym)[(N*percA+N*percB+1):(N*percA+N*percB+N*percC)] <- rep("Agent C",N*percC)

```

A plot of the extension:

```{r extension 1 plot, echo=FALSE, warning=FALSE}
matplot(t(sym), ylim = c(0,1.4), type = c("b"),pch=1,col = as.factor(sym[,t+1])) #plot
legend("topright", legend = unique(sym[,t+1]), col=1:3, pch=19, bty ="n") # optional legend
```

## Extension 2

> Description, equations etc.

## Some summary

summary here

## References

1.  Ref1
2.  Ref2 ...
